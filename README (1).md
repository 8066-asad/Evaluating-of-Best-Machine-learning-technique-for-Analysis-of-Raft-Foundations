# ğŸ—ï¸ Enhanced Machine Learning Model Evaluation for Raft Foundation Analysis

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![Google Colab](https://img.shields.io/badge/Google-Colab-blue.svg)](https://colab.research.google.com)

---
 
## ğŸ“Œ Project Overview

This project provides a **comprehensive machine learning framework** for evaluating regression models to predict critical geotechnical parameters of **raft foundations**. It serves as a powerful tool for civil engineers and geotechnical specialists to optimize foundation design through data-driven insights.

### ğŸ¯ Target Predictions

- **Settlement (mm)** - Foundation displacement under load
- **Punching Shear Value** - Shear capacity at critical sections
- **Bearing Pressure (kPa)** - Contact pressure distribution

### ğŸ”¬ Key Capabilities

The framework includes robust **data preprocessing**, **feature engineering**, and **multi-model comparisons** under different scaling techniques. The primary goal is to **identify the most accurate and generalizable ML model** for foundation behavior prediction and design optimization.

---

## ğŸš€ Features

### ğŸ¤– Machine Learning Models
- **13+ Regression Algorithms** including:
  - Linear Models: Linear Regression, Ridge, Lasso, ElasticNet
  - Tree-based: Decision Tree, Random Forest, Extra Trees
  - Gradient Boosting: XGBoost, LightGBM, CatBoost
  - Advanced: Support Vector Regression, K-Nearest Neighbors, Neural Networks

### ğŸ“Š Multi-Output Regression
- **Simultaneous prediction** of multiple target variables
- Essential for comprehensive foundation design analysis

### ğŸ”§ Data Processing & Feature Engineering
- **Multiple Scaling Techniques**: StandardScaler, MinMaxScaler, RobustScaler
- **Domain-informed feature engineering** for geotechnical applications
- **SelectKBest feature selection** for optimal model performance
- **Comprehensive outlier detection** and handling

### ğŸ“ˆ Evaluation & Metrics
- **Comprehensive metrics** for each target:
  - RÂ², MSE, RMSE, MAE
  - Cross-validation RÂ² with statistical significance
  - Training RÂ² for overfitting detection
- **Performance comparison** across all model-scaler combinations

### ğŸ” Model Interpretability
- **Feature importance analysis**:
  - Tree-based importance for ensemble methods
  - Permutation importance for model-agnostic interpretation
- **Correlation analysis** with publication-ready heatmaps

### âš™ï¸ Advanced Features
- **Automated hyperparameter tuning** using GridSearchCV
- **Model persistence** for production deployment
- **Interactive prediction interface** for new data
- **Comprehensive visualizations** for model validation

### ğŸ“Š Visualization Suite
- Correlation heatmaps with statistical significance
- Actual vs. predicted scatter plots with regression lines
- Residual analysis plots
- Model performance comparison charts
- Feature importance visualizations

---

## ğŸ› ï¸ Installation & Setup

### ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Jupyter Notebook** or **Google Colab** (recommended)
- **8GB+ RAM** recommended for optimal performance

### ğŸ”§ Environment Setup

#### Option 1: Virtual Environment (Recommended)
```bash
# Create and activate virtual environment
python -m venv raft_foundation_env
source raft_foundation_env/bin/activate  # Linux/Mac
# or
raft_foundation_env\Scripts\activate     # Windows
```

#### Option 2: Conda Environment
```bash
conda create -n raft_foundation python=3.8
conda activate raft_foundation
```

### ğŸ“¦ Dependencies Installation

```bash
# Core ML and data processing libraries
pip install pandas numpy scikit-learn

# Advanced ML models
pip install xgboost lightgbm catboost

# Visualization libraries
pip install matplotlib seaborn

# Data handling
pip install openpyxl

# Optional: Enhanced progress tracking
pip install tqdm

# For Jupyter environments
pip install ipywidgets
```

Or install all at once:
```bash
pip install pandas numpy scikit-learn xgboost lightgbm catboost matplotlib seaborn openpyxl tqdm ipywidgets
```

---

## ğŸ“š Usage Guide

### ğŸš€ Quick Start

#### Step 1: Data Preparation
```python
from google.colab import files
uploaded = files.upload()  # Upload your Excel file
```

#### Step 2: Run Analysis
Execute the complete analysis pipeline by running all cells in the notebook. The system will automatically:

1. **Load and validate** your dataset
2. **Explore and preprocess** the data
3. **Engineer relevant features** for foundation analysis
4. **Train and evaluate** all model combinations
5. **Select the best performing** model
6. **Generate comprehensive reports** and visualizations

### ğŸ“Š Dataset Requirements

Your Excel file should contain the following columns:
- `Number of Columns`
- `Area Of Raft (m^2)`
- `Column Area (m^2)`
- `Compressive strength of Concrete Fc' (Mpa)`
- `Concrete Unit Weight (kN/m^3)`
- `Subgrade Modulus kN/m/m^2`
- `Maximum Axial Load on Column in kN`
- `Total Axial load on Column (kN)`
- `Thickness of Raft (mm)`
- `Settlement (mm)` (target)
- `Punching Shear Value` (target)
- `Bearing Pressure (kPa)` (target)

### ğŸ”® Making Predictions

After training, use the saved model for new predictions:

```python
import pickle
import pandas as pd

# Load the trained model
with open('best_model.pkl', 'rb') as f:
    model = pickle.load(f)

with open('best_scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Make predictions on new data
# See detailed example in the code documentation
```

---

## ğŸ—ï¸ Code Architecture

The project follows a modular, sequential structure optimized for Jupyter environments:

```
â”œâ”€â”€ ğŸ“ Data Loading & Validation
â”œâ”€â”€ ğŸ“ Exploratory Data Analysis
â”œâ”€â”€ ğŸ“ Feature Engineering
â”œâ”€â”€ ğŸ“ Model Training Pipeline
â”œâ”€â”€ ğŸ“ Performance Evaluation
â”œâ”€â”€ ğŸ“ Model Selection & Tuning
â”œâ”€â”€ ğŸ“ Visualization & Reporting
â””â”€â”€ ğŸ“ Model Persistence & Deployment
```

### ğŸ”„ Workflow Overview

1. **Data Ingestion**: Load Excel data with validation
2. **EDA**: Statistical analysis, outlier detection, correlation study
3. **Feature Engineering**: Domain-specific feature creation
4. **Model Training**: Automated training across multiple algorithms
5. **Evaluation**: Comprehensive performance assessment
6. **Selection**: Best model identification using statistical criteria
7. **Validation**: Cross-validation and residual analysis
8. **Deployment**: Model saving and prediction interface

---

## ğŸ“Š Performance Metrics

### ğŸ“ˆ Evaluation Criteria

| Metric | Description | Interpretation |
|--------|-------------|----------------|
| **RÂ²** | Coefficient of determination | > 0.8: Excellent, > 0.6: Good |
| **RMSE** | Root Mean Square Error | Lower is better |
| **MAE** | Mean Absolute Error | Average prediction error |
| **Cross-Val RÂ²** | Cross-validation score | Model generalization ability |

### ğŸ¯ Model Selection

The framework automatically selects the best model based on:
- **Average RÂ² across all targets** (primary criterion)
- **Cross-validation stability**
- **Training vs. validation performance** (overfitting detection)
- **Computational efficiency**

---

## ğŸ”§ Advanced Configuration

### âš™ï¸ Hyperparameter Tuning

The framework includes predefined hyperparameter grids for major algorithms:

```python
# Example for XGBoost
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 0.9, 1.0]
}
```

### ğŸ” Feature Selection

Customize feature selection parameters:
```python
# Adjust number of features to select
selector = SelectKBest(score_func=f_regression, k=10)
```

### ğŸ“Š Visualization Options

Control visualization output:
```python
# Minimum RÂ² threshold for detailed plots
min_r2_threshold = 0.5

# Plot customization
plot_style = 'seaborn'
figure_size = (12, 8)
```

---

## ğŸ¤ Contributing

We welcome contributions from the geotechnical and machine learning communities!

### ğŸ”„ Development Process

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### ğŸ“ Contribution Guidelines

- Follow **PEP 8** Python style guidelines
- Add **comprehensive documentation** for new features
- Include **unit tests** for critical functions
- Update **README** for significant changes
- Ensure **backward compatibility**

### ğŸ› Bug Reports

Please include:
- Python version and OS
- Complete error traceback
- Minimal example to reproduce
- Expected vs. actual behavior

---

## ğŸ“– Documentation

### ğŸ“š Additional Resources

- **Jupyter Notebook**: Complete implementation with detailed explanations
- **Code Comments**: Comprehensive inline documentation
- **Function Docstrings**: API documentation for all functions
- **Performance Reports**: Automated model comparison tables

### ğŸ”¬ Research Applications

This framework has been successfully applied to:
- **Foundation design optimization**
- **Geotechnical parameter prediction**
- **Construction cost estimation**
- **Risk assessment in foundation engineering**

---

## ğŸ›¡ï¸ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### ğŸ“„ MIT License Summary

```
MIT License

Copyright (c) 2024 Muhammad Asad Sardar

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

- **Geotechnical Engineering Community** for domain expertise
- **Scikit-learn Team** for the machine learning framework
- **XGBoost, LightGBM, CatBoost** developers for advanced algorithms
- **Matplotlib & Seaborn** for visualization capabilities

---

## ğŸ“ Support & Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/raft-foundation-ml/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/raft-foundation-ml/discussions)
- **Email**: your.email@example.com

---

## ğŸ”— Quick Links

- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“¦ Installation](#-dependencies-installation)
- [ğŸ“Š Usage Guide](#-usage-guide)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“– Documentation](#-documentation)

---

*Built with â¤ï¸ for the geotechnical engineering community*
## Acknowledgements

 - [Awesome Readme Templates](https://awesomeopensource.com/project/elangosundar/awesome-README-templates)
 - [Awesome README](https://github.com/matiassingers/awesome-readme)
 - [How to write a Good readme](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)

